<p align="center">
<h1 align="center"><strong> ChatStitch: Visualizing Through Structures via Surround-View Unsupervised Deep Image Stitching with Collaborative LLM-Agents</strong></h1>
</p>



<p align="center">
  <a href="https://inin-drops.github.io/UVM-VSS/" target='_blank'>
    <img src="https://img.shields.io/badge/Project-üëî-green?">
  </a> 
  
  <a href="https://arxiv.org/pdf/2503.14948" target='_blank'>
    <img src="https://img.shields.io/badge/Paper-üìñ-blue?">
  </a> 
  
  <a href="https://youtu.be/CqoVZQdvxU4" target='_blank'>
    <img src="https://img.shields.io/badge/Video-üìπ-red?">
  </a> 
</p>


 ## üè†  Abstract
Human-machine co-driving has garnered significant attention for its ability to enhance driving efficiency through collaborative information exchange between human drivers and intelligent vehicles. However, existing human-machine co-driving systems are limited by inefficiencies in unidirectional interaction pattern and the absence of cognitively aligned visualization mechanisms. To address these challenges, this paper introduces ChatStitch, a human-machine co-perception system capable of unveiling obscured blind spot information through natural language commands integrated with external digital assets. To establish natural human-machine dialogue, ChatStitch implements a cognitively grounded closed-loop interaction framework based on Large Language Models. For bridging the dissociation between machine vision and human perception, ChatStitch proposes SV-UDIS, a surround-view unsupervised deep image stitching method under the non-global-overlapping condition. We conducted extensive experiments on the UDIS-D, MCOV-SLAM open datasets, and our real-world dataset. Specifically, our SV-UDIS method achieves state-of-the-art performance on the UDIS-D dataset for 3, 4, and 5 image stitching tasks, with PSNR improvements of 9\%, 17\%, and 21\%, and SSIM improvements of 8\%, 18\%, and 26\%, respectively.
<img src="https://github.com/lhlawrence/UVM-VSS/blob/main/poster.png">


## üõ†  Install

The code is coming soon.

## üîó Citation

If you find our work helpful, please cite:

```bibtex
@article{ChatStitch,
      title={ChatStitch: Visualizing Through Structures via Surround-View Unsupervised Deep Image Stitching with Collaborative LLM-Agents}, 
      author={Hao Liang and Zhipeng Dong and Yi Yang and Mengyin Fu},
      year={2025},
      eprint={2503.14948},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2503.14948}, 
}
```

## üëè Acknowledgements
We would like to express our gratitude to All ININ members for their support and encouragement. 
